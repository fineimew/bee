---
title: OPQ Information Architecture
sidebar_label: OPQ Information Architecture
---


OPQ's "information architecture" is designed to facilitate the process of generating actionable, useful insights into the nature of the electrical grid starting with the data collected from a wall outlet. It is a five layer architecture in which data in the form of *Measurements* collected by an OPQ Box can eventually yield insights in the form of *Phenomena*.  (The Incident and Phenomena levels are currently in development.)

The following table provides an overview of the five layers from lowest level (Box) to highest level (Phenomena).  "TTL", to Time To Live, indicates how long entities at each level are stored before they are automatically deleted.

| Layer | TTL |  Purpose |
| ------| --- |  ------- |
| Box | 1 hour | Collects and holds a rolling one hour window of "high fidelity" wave form data for a single location. |
| Measurement | 1 day | Approximately once a second, each box sends a Measurement to OPQ Cloud. Measurements provides "low fidelity" summary statistics regarding four power measurements (Frequency, Voltage, THD, Transients). Measurements give OPQ Cloud basic situational awareness of the grid without the overhead of transmitting and storing wave form data. Measurements exist for one day, though a daily roll-up of Measurement summary statistics called "Trends" persists much longer.  |
| Event    | 1 month | When OPQ Cloud's Makai service detects non-nominal values in the stream of Measurements, it can decide to request wave form data from one or more boxes for a specific time interval (typically just a second or so). Note that Makai only has one hour to request high fidelity wave form data before it is written over in the Box.   |
| Incident | 6 months | Not every non-nominal power data value is significant, i.e. actually meaningful for gaining insight into the grid.  Over the years, electrical engineers have developed a variety of standards (IEEE 1159, ITIC, SEMA, etc.) for characterizing significant power quality events.  OPQ Cloud's Mauka service provides classification algorithms to analyze each Event to see if it satisfies any of the standards for significance. If so, an Incident is created, indicating that a significant PQ event has occurred at a specific time in a specific location.  <br/><br/> Each Incident can also be annotated with *context*, which is additional information about the environment or other physical factors present at the time and location of this incident. Context can be manually provided by users or automatically associated with Incidents through APIs to online services.   |
| Phenomena  | 1 year | All of the prior levels represent behaviors of a individual Boxes in a single location at a given point in time.  This final level of OPQ's information architecture is premised on the idea that insightful, actionable information results from the ability to either *explain* or else *predict* multiple Incidents.  <br/><br/>First, a Phenomena can be created in order to collect data from multiple Incidents with a common cause. An example of this form of phenomena is "the voltage drop experienced by all boxes in Kailua on 5/22/18 at 1:03pm was caused by a transformer trip at the Kailua substation." <br/><br/>Second, a Phenomena can collect data from multiple Incidents in order to predict future Incidents. For example, "when winds exceed 40 knots in Kahuku, data from prior Incidents leads to the prediction that there will be a voltage surge of approximately 5V for approximately 3 seconds in all boxes located within 1 mile of Kahuku." |

The OPQ information architecture embodies a "use it or lose it" principle for data retention. As shown above, all entities at all levels of the information architecture have a "TTL", or time-to-live, which means that all entities are automatically deleted after a certain period of time.  We make this decision in order to avoid unbounded growth of the underlying database, as well as to maintain a reasonable signal-to-noise ratio in the database. 

The fact that entities have a TTL means that useful data must always be "copied upward". For example, when an Incident is created, it must provide within its representation all pertinent data from any underlying Events, because every Event will eventually be deleted. Even Phenomena are not permanent: all causal and predictive hypotheses must be "renewed" at least once a year in order to remain in the system. 
